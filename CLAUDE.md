# AI Audit Platform - Workflow-Driven Development Guide

> **Version**: 2.0.0
> **Last Updated**: 2026-01-06
> **Purpose**: Modular workflow guide with streamlined core principles and external reference documentation

---

## ðŸ“‹ Table of Contents

1. [ðŸŽ¯ Core Philosophy (READ THIS FIRST)](#-core-philosophy-read-this-first)
2. [How This Guide Works](#how-this-guide-works)
3. [Quick Start Guide](#quick-start-guide)
4. [Subagent Orchestration](#subagent-orchestration)
5. [Global Infrastructure](#global-infrastructure)
6. [Emergency Procedures](#emergency-procedures)
7. [Best Practices](#best-practices)
8. [Quick Reference](#quick-reference)
9. [ðŸ“š External References](#-external-references)

---

## ðŸŽ¯ Core Philosophy (READ THIS FIRST)

### Context Preservation is CRITICAL

**Main conversation context** is precious and limited. To preserve it:
- âœ“ **DEFAULT to subagents** for ANY non-trivial work (>5 min)
- âœ“ **Offload execution** to subagents, keep only oversight in main context
- âœ“ **Main agent role**: Architecture design, orchestration, review
- âœ— **NEVER execute** long implementations directly in main conversation

### Aggressive Parallelization (CPU is NOT a constraint)

**Hardware assumption**: Sufficient CPU for 10+ simultaneous subagents

**Parallel execution rules**:
1. **10+ subagents is NORMAL** for complex features (not excessive)
2. **Launch ALL independent tasks** in SINGLE message
3. **No artificial limits** - use as many subagents as needed
4. **Time = MAX(slowest)** not SUM(all) - exploit this!

**Example**: Feature with 15 independent subtasks
- âœ“ Spawn all 15 in parallel â†’ Total time: ~15-30 min
- âœ— Do sequentially â†’ Total time: ~225 min (15 Ã— 15min)
- **Savings**: 87-93% faster!

### Hierarchical Review Process

**Quality gates at every level**:

```
Main Agent (Architecture + Final Review)
   â†“ spawns 10+ subagents
Subagent Layer 1 (Implementation + Initial Validation)
   â†“ each can spawn sub-subagents if needed
Sub-subagent Layer 2 (Granular tasks + Unit validation)
   â†“
PostToolUse Hook (Automatic validation at ALL layers)
```

**Example hierarchy**:
```
Main: Implement dashboard feature
â”œâ”€ Subagent 1: Types + Type Tests
â”‚  â”œâ”€ Sub 1a: Interface definitions
â”‚  â””â”€ Sub 1b: Type unit tests
â”œâ”€ Subagent 2: Main Component + Component Tests
â”‚  â”œâ”€ Sub 2a: Component implementation
â”‚  â”œâ”€ Sub 2b: Component unit tests
â”‚  â””â”€ Sub 2c: Component integration tests
â”œâ”€ Subagent 3-7: Sub-components (5 parallel)
â”œâ”€ Subagent 8-10: Hooks + Hook Tests (3 parallel)
â”œâ”€ Subagent 11: Mock Data + Data Tests
â”œâ”€ Subagent 12: Integration + Routing
â”œâ”€ Subagent 13: Styling + Responsive Tests
â”œâ”€ Subagent 14: E2E Tests
â””â”€ Subagent 15: Documentation

Total: 15 parallel subagents (some with sub-subagents)
Time: ~20-30 min (not 15Ã—15min = 225min!)
Main context used: Minimal (only orchestration)
```

### When to NOT Use Subagents (Rare)

**ONLY do directly if ALL conditions met**:
1. Task is trivial (<5 min)
2. Task cannot be parallelized
3. Task requires real-time user interaction (AskUserQuestion)
4. Task is purely conversational/explanatory

**Examples**:
- âœ“ Direct: "Explain what this function does" (conversational)
- âœ“ Direct: "Add one console.log line" (<5 min)
- âœ— Subagent: "Fix type errors" (use subagent even if seems small)
- âœ— Subagent: "Write tests" (ALWAYS use subagent for testing)

---

## How This Guide Works

### Session Lifecycle & Auto-Loading

**CRITICAL**: This CLAUDE.md file is **automatically loaded** at the start of EVERY session:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session Start (New or Resumed)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CLAUDE.md Auto-Loaded                  â”‚
â”‚  (via system context injection)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Session Initialization Hook            â”‚
â”‚  (reads metrics, git status, etc.)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ready to Execute Workflows             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**When CLAUDE.md is loaded:**
- âœ“ Every new session start
- âœ“ When conversation context is summarized (token limit reached)
- âœ“ When session is resumed after interruption
- âœ“ **NO explicit user request needed** - it's automatic

**What this means:**
- All workflows, slash commands, and best practices are ALWAYS available
- Claude automatically follows these guidelines without being told
- Consistency across all sessions guaranteed

---

### Automatic Tool & Technology Usage

**MCP Servers** (Model Context Protocol):

Claude automatically uses MCP servers **WITHOUT explicit user request** when appropriate:

### MCP Auto-Use Logic (IF-THEN Pattern Matching)

```
Parse user query
    â†“
IF (query about library OR framework OR API documentation)
   â†’ Auto-use: Context7 MCP
   â†’ Action: resolve-library-id â†’ query-docs
   â†’ Example: "How do I use React 19's useActionState?"
   â†“
ELSE IF (PR review OR code review OR GitHub analysis)
   â†’ Auto-use: Greptile MCP
   â†’ Action: list_pull_requests â†’ get_merge_request â†’ list_merge_request_comments
   â†’ Example: "Review the open PR for authentication changes"
   â†“
ELSE IF (browser|scraping|screenshot|UI testing)
   â†’ Auto-use: Playwright MCP
   â†’ Action: browser_navigate â†’ browser_snapshot â†’ browser_take_screenshot
   â†’ Example: "Take a screenshot of localhost:5173"
   â†“
ELSE IF (LangChain|LangGraph|RAG|agent workflow)
   â†’ Auto-use: langchain-docs MCP
   â†’ Action: list_doc_sources â†’ fetch_docs
   â†’ Example: "How do I create a LangGraph agent with memory?"
   â†“
ELSE IF (semantic code search OR symbol navigation OR refactoring)
   â†’ Auto-use: Serena MCP
   â†’ Action: find_symbol â†’ find_referencing_symbols â†’ replace_symbol_body
   â†’ Example: "Find all references to UserAuth class"
   â†“
ELSE IF (complex problem solving OR debugging OR architectural decisions)
   â†’ Auto-use: Sequential Thinking MCP
   â†’ Action: Multi-step reasoning with hypothesis generation and verification
   â†’ Example: "Why is my React component re-rendering infinitely?"
```

**Example - Automatic MCP Usage**:
```
User: "How do I use React 19's new useActionState hook?"
Claude: [Automatically uses Context7 MCP to get latest React docs]
        [NO need for user to say "use Context7" or "/context7"]
```

**For detailed MCP documentation**, see: [MCP Integration Guide](.claude/docs/MCP-GUIDE.md)

**Slash Commands & Skills**:

Claude automatically invokes slash commands/skills when the task matches their purpose:

```
User: "Implement a dashboard feature"
Claude: [Automatically executes /plan-implement-verify workflow]
        [NO need for user to type "/plan-implement-verify"]

User: "Commit my changes"
Claude: [Automatically executes /commit-push-pr]
        [NO need for user to type "/commit-push-pr"]

User: "Review my code quality"
Claude: [Automatically executes /validate-architecture]
        [NO need for user to type "/validate-architecture"]
```

**Auto-Invoked Skills**:

Claude automatically uses skills from three sources:
1. **SuperClaude Skills** (`/sc:*`) - Advanced orchestration and analysis
2. **Installed Plugins** - Official and community plugins
3. **Custom User Skills** - Project-specific workflows

### SuperClaude Skills (Intelligent Orchestration)

| Skill | Auto-Use Trigger | Purpose |
|-------|------------------|---------|
| `/sc:implement` | Feature implementation request | Persona activation for implementation with MCP integration |
| `/sc:analyze` | Code analysis request | Comprehensive quality, security, performance, architecture analysis |
| `/sc:troubleshoot` | Bug/error diagnosis needed | Systematic diagnosis and resolution |
| `/sc:improve` | Code quality improvement | Apply systematic improvements (refactoring, optimization) |
| `/sc:explain` | Code explanation needed | Educational clarity on code/concepts/systems |
| `/sc:design` | Architecture design needed | Design system architecture, APIs, component interfaces |
| `/sc:test` | Testing request | Execute tests with coverage analysis and quality reporting |
| `/sc:research` | Research/investigation needed | Deep web research with adaptive planning |
| `/sc:workflow` | Complex multi-step task | Generate structured implementation workflows |
| `/sc:brainstorm` | Requirements discovery | Interactive Socratic dialogue for requirements |

### Installed Plugin Skills

| Skill | Auto-Use Trigger | Purpose |
|-------|------------------|---------|
| **Code Review & Development** | | |
| `code-review:code-review` | PR review request | Automated code review of pull requests |
| `feature-dev:feature-dev` | Complex feature development | Guided feature development with codebase understanding |
| `validate-architecture` | Before commit or quality check | Deep architecture analysis (OOP, clean code, file size) |
| **Document Generation** | | |
| `document-skills:pdf` | PDF manipulation needed | Extract, create, merge PDFs; fill forms |
| `document-skills:xlsx` | Spreadsheet work needed | Create/edit spreadsheets with formulas, formatting |
| `document-skills:pptx` | Presentation needed | Create/edit PowerPoint presentations |
| `document-skills:doc-coauthoring` | Documentation writing | Structured workflow for co-authoring docs, specs |
| `document-skills:theme-factory` | Styling artifacts | Apply themes to slides, docs, reports, HTML pages |
| **Notion Integration** | | |
| `Notion:notion-search` | Search Notion workspace | Find pages, databases in Notion |
| `Notion:notion-create-page` | Create Notion page | Add new pages to Notion workspace |
| `Notion:notion-create-task` | Create Notion task | Add tasks to Notion tasks database |
| `Notion:notion-database-query` | Query Notion database | Retrieve structured data from Notion databases |
| **Agent & Plugin Development** | | |
| `agent-sdk-dev:new-sdk-app` | Create Agent SDK app | Setup new Claude Agent SDK application (TypeScript/Python) |
| `plugin-dev:create-plugin` | Create plugin | End-to-end plugin creation with component design |
| **LLM & AI Application Development** | | |
| `llm-application-dev:ai-engineer` | LLM application/agent building | Production-ready LLM apps, RAG systems, intelligent agents |
| `llm-application-dev:prompt-engineer` | Prompt optimization needed | Advanced prompting, chain-of-thought, prompt strategies |
| `llm-application-dev:vector-database-engineer` | Vector search/embeddings | Vector databases, semantic search, embeddings optimization |

### Custom User Skills (Project Workflows)

| Skill | Auto-Use Trigger | Purpose |
|-------|------------------|---------|
| **Requirements Discovery** | | |
| `/interview` | **NEW feature OR architecture improvement** | **Deep requirements interview (RUNS FIRST, triggers plan mode)** |
| **Development Workflows** | | |
| `/worktree-setup` | Feature/bugfix start | Create isolated git worktree for parallel development |
| `/plan-implement-verify` | Feature implementation | Full 6-phase development cycle (plan â†’ implement â†’ validate) |
| `/validate-architecture` | Before commit | Architecture validation (unnecessary lines, OOP, file size) |
| `/commit-push-pr` | Ready to commit | Complete git workflow (stage â†’ commit â†’ push â†’ PR) |
| `/subagent-spawn` | Granular task delegation | Launch focused subagent for specific file/module task |
| `/feedback-capture` | After workflow completion | Record metrics for continuous improvement |

**CRITICAL: `/interview` Priority**

The `/interview` skill **MUST run FIRST** for:
- âœ“ New feature requests (any feature, regardless of complexity)
- âœ“ Architecture improvements or refactoring
- âœ“ Complex bug fixes with unclear requirements
- âœ“ When user requirements are ambiguous or incomplete

**What `/interview` Does**:
1. **Reads plan file** (if exists) to understand initial context
2. **Conducts deep interview** using AskUserQuestion tool:
   - Technical implementation details (API design, data structures, algorithms)
   - UI/UX design decisions (user flows, visual design, accessibility)
   - Potential concerns and edge cases (error handling, boundary conditions, race conditions)
   - Architecture and design tradeoffs (scalability, maintainability, performance)
3. **Asks non-superficial questions** - goes deep, not obvious/shallow
4. **Continues until complete understanding** - doesn't stop prematurely
5. **Writes comprehensive specification document** - detailed spec with all decisions documented
6. **Enters plan mode** automatically after interview completion

**Interview â†’ Plan â†’ Implement Flow**:
```
User: "Implement a real-time notification system"
  â†“
STEP 1: /interview (AUTOMATIC, FIRST)
  â†’ Ask: "What types of notifications? (push, email, in-app?)"
  â†’ Ask: "How should notifications be prioritized?"
  â†’ Ask: "What happens if user is offline?"
  â†’ Ask: "Should notifications be grouped/batched?"
  â†’ Ask: "What's the expected notification volume per user?"
  â†’ Ask: "How do we handle notification permissions?"
  â†’ ... (continues until complete understanding)
  â†’ Output: comprehensive-notification-spec.md
  â†“
STEP 2: Enter Plan Mode (AUTOMATIC)
  â†’ Use spec to design architecture
  â†’ Break down into 5-8 granular tasks
  â†’ Get user approval
  â†“
STEP 3: /plan-implement-verify
  â†’ Execute implementation with full context
```

**Why Interview First?**
- âŒ **Without interview**: Assumptions, missing requirements, rework
- âœ“ **With interview**: Clear requirements, informed decisions, correct implementation first time

**Example Questions from `/interview`**:

```
BAD (superficial):
âŒ "Should we add a dashboard?"
âŒ "Do you want this to be fast?"
âŒ "Should it look good?"

GOOD (deep, technical):
âœ“ "What metrics are most critical for users to see at-a-glance vs. drill-down?"
âœ“ "How should we handle data refresh - polling interval, WebSocket, SSE?"
âœ“ "What's the acceptable latency for real-time updates - <100ms, <1s, <5s?"
âœ“ "How do we gracefully degrade if the backend is slow/unavailable?"
âœ“ "What's the data retention policy - how far back should historical data go?"
```

### Skill Selection Logic

**How Claude Chooses**:

### Skill Selection Logic (IF-THEN Execution)

```
Parse user request
    â†“
IF (new feature OR architecture improvement OR unclear refactoring scope)
   â†’ TIER 0: Execute /interview (mandatory first step)
   â†’ Output: Comprehensive specification document
   â†’ Action: Enter plan mode automatically
   â†“
ELSE IF (implement|feature|build) + (component|page|system)
   â†’ TIER 1: Execute /plan-implement-verify (after /interview)
   â†’ Within workflow: Uses /sc:design for architecture, /sc:implement for code
   â†“
ELSE IF (review PR OR code review)
   â†’ TIER 3: Execute code-review:code-review
   â†’ No /interview needed (not new feature)
   â†“
ELSE IF (analyze OR performance OR security)
   â†’ TIER 2: Execute /sc:analyze
   â†’ May also use /validate-architecture
   â†’ No /interview needed (analysis task)
   â†“
ELSE IF (fix|bug|error) + (clear symptoms)
   â†’ TIER 2: Execute /sc:troubleshoot
   â†’ No /interview needed (clear bug fix)
   â†“
ELSE IF (fix|bug) + (unclear root cause)
   â†’ TIER 0: Execute /interview (get symptoms, expected behavior)
   â†’ TIER 2: Execute /sc:troubleshoot with full context
   â†“
ELSE IF (research|investigate|best practices)
   â†’ TIER 2: Execute /sc:research
   â†’ Auto-uses Context7 MCP for documentation
   â†’ No /interview needed (research task)
   â†“
ELSE IF (document generation: spreadsheet|pdf|presentation)
   â†’ TIER 3: Execute document-skills:* (xlsx, pdf, pptx)
   â†’ No /interview needed (straightforward document generation)
   â†“
ELSE IF (LLM application: RAG|agent|vector search)
   â†’ TIER 0: Execute /interview (data sources, architecture, strategy)
   â†’ TIER 3: Execute llm-application-dev:ai-engineer
   â†’ Auto-uses llm-application-dev:vector-database-engineer
   â†’ Auto-uses langchain-docs MCP
```

**Priority Order** (when multiple skills match):

**TIER 0 (HIGHEST PRIORITY - Runs BEFORE everything else)**:
- **`/interview`** - Requirements discovery for new features/architecture
  - Triggers automatically for: new features, architecture changes, refactoring
  - **ALWAYS runs before planning or implementation**
  - Outputs: comprehensive specification document
  - Action: Enters plan mode after completion

**TIER 1 (Custom User Skills)** - Project-specific workflows:
- **`/plan-implement-verify`** - Full development cycle (after /interview)
- **`/worktree-setup`** - Git worktree creation
- **`/validate-architecture`** - Architecture validation
- **`/commit-push-pr`** - Git workflow automation

**TIER 2 (SuperClaude Skills)** - Intelligent orchestration:
- `/sc:implement`, `/sc:design`, `/sc:analyze`, `/sc:research`, etc.

**TIER 3 (Plugin Skills)** - Specialized capabilities:
- `code-review:code-review`, `document-skills:*`, `llm-application-dev:*`, etc.

**Example Automatic Selection**:

```
User: "Implement a dashboard with metrics visualization"
â†’ STEP 1: /interview (TIER 0 - runs FIRST)
   â†’ Deep questions about metrics, refresh rates, user workflows, etc.
   â†’ Output: dashboard-spec.md
â†’ STEP 2: Enter plan mode automatically
â†’ STEP 3: /plan-implement-verify (TIER 1)
   â†’ Within workflow: Uses /sc:design for architecture, /sc:implement for code

User: "Refactor authentication system for better scalability"
â†’ STEP 1: /interview (TIER 0 - architecture improvement)
   â†’ Questions about current bottlenecks, scale requirements, auth patterns
   â†’ Output: auth-refactor-spec.md
â†’ STEP 2: Enter plan mode
â†’ STEP 3: Execute refactoring workflow

User: "Review the PR for authentication changes"
â†’ Auto-selects: code-review:code-review (TIER 3 plugin)
â†’ No interview needed (not new feature, just review)

User: "Analyze this component for performance issues"
â†’ Auto-selects: /sc:analyze (TIER 2 SuperClaude)
â†’ May also use: /validate-architecture for architecture issues
â†’ No interview needed (analysis task, not implementation)

User: "Create a report spreadsheet with sales data"
â†’ Auto-selects: document-skills:xlsx (TIER 3 plugin)
â†’ No interview needed (straightforward document generation)

User: "Research best practices for React Server Components"
â†’ Auto-selects: /sc:research (TIER 2 SuperClaude)
â†’ Auto-uses: Context7 MCP for documentation
â†’ No interview needed (research task, not implementation)

User: "Build a RAG system with vector search"
â†’ STEP 1: /interview (TIER 0 - new feature)
   â†’ Questions about data sources, embedding models, retrieval strategy
   â†’ Output: rag-system-spec.md
â†’ STEP 2: Enter plan mode
â†’ STEP 3: llm-application-dev:ai-engineer (TIER 3 plugin)
   â†’ Auto-uses: llm-application-dev:vector-database-engineer
   â†’ Auto-uses: langchain-docs MCP for documentation
â†’ Result: Complete RAG implementation

User: "Fix login bug - users can't sign in"
â†’ Auto-selects: /sc:troubleshoot (TIER 2 SuperClaude)
â†’ No interview needed (clear bug fix, not new feature)

User: "Fix authentication - it's not working properly but unclear why"
â†’ STEP 1: /interview (TIER 0 - unclear requirements)
   â†’ Questions about symptoms, expected behavior, edge cases
   â†’ Output: auth-bug-spec.md
â†’ STEP 2: /sc:troubleshoot with full context
```

**Override Behavior**:
If you want to disable automatic invocation for a specific task, explicitly say:
- "Don't use any slash commands, just do X manually"
- "Skip the normal workflow and directly Y"

---

### External Reference Loading Protocol

**RULE**: Some docs are auto-loaded via hooks, others require manual Read.

#### Auto-Loaded Docs (Already in Context)

The following docs are **automatically injected at session start** via `~/.claude/hooks/pre-session-start.sh`:

1. âœ“ **WORKFLOW-1-FEATURE-IMPLEMENTATION.md** (477 lines)
   - When to use: Feature implementation with 10-15 parallel subagents
   - Phases: Planning, Worktree Setup, Parallel Implementation, Validation, Commit-Push-PR, Feedback

2. âœ“ **WORKFLOW-2-BUG-FIX.md** (88 lines)
   - When to use: Bug fixes (fast-track 10-20 min resolution)
   - Phases: Diagnosis, Worktree Setup, Fix, Validation, Commit-Push-PR, Feedback

3. âœ“ **WORKFLOW-3-REFACTORING.md** (95 lines)
   - When to use: Code quality improvements, architecture refactoring
   - Phases: Analysis, Worktree Setup, Refactoring, Before/After Comparison, Commit-Push-PR, Feedback

4. âœ“ **TESTING-GUIDE.md** (325 lines)
   - When to use: Writing tests, checking coverage, test methodology
   - Content: Test pyramid, unit/integration/E2E testing, coverage requirements, assertions

5. âœ“ **PROJECT-CONTEXT.md** (189 lines)
   - When to use: Code quality checks, SOLID principles, file size limits, type safety
   - Content: Tech stack, file organization, code quality standards, size constraints

**Total auto-loaded**: 1,174 lines (~4,700 tokens per session)

**Action**: âœ“ These docs are ALWAYS available - DO NOT use Read tool for them.

---

#### Context-Sensitive Docs (Auto-Loaded by Pre-Tool-Use Hook)

The following doc is **automatically injected when relevant tool detected** via `~/.claude/hooks/pre-tool-use.sh`:

1. **SETUP.md** (149 lines)
   - **Trigger**: Bash tool with backend keywords (manage.py, pytest, python, venv, pip)
   - **Content**: Python venv activation, server management, port checking
   - **Action**: âœ“ Auto-loaded when you use backend tools - no manual Read needed

---

#### Manual Read Required (Context-Dependent)

The following docs are NOT auto-loaded and REQUIRE manual Read:

**1. MCP Integration** (when MCP servers mentioned):
```
IF (user mentions Context7|Greptile|Serena|Playwright|Sequential Thinking|LangChain|MCP)
   â†’ Read(.claude/docs/MCP-GUIDE.md)
   â†’ Content: MCP auto-use triggers, tool sequences, best practices (460 lines)
```

**2. Loop Prevention** (when emergency detected):
```
IF (stuck state|infinite loop|ralph-wiggum triggered|>10 tool calls without progress)
   â†’ Read(.claude/docs/workflows/WORKFLOW-4-LOOP-PREVENTION.md)
   â†’ Content: Recovery sequence, decision tree, resume strategy (88 lines)
```

**3. Templates** (when specific template needed):
```
IF (need commit message format)
   â†’ Read(.claude/prompts/commit-message.md)

IF (need PR description format)
   â†’ Read(.claude/prompts/pr-description.md)

IF (need architecture review checklist)
   â†’ Read(.claude/prompts/architecture-review.md)

IF (need subagent spawn template)
   â†’ Read(.claude/prompts/subagent-spawn.md)

IF (need workflow breakdown template)
   â†’ Read(.claude/prompts/workflow-breakdown.md)
```

---

#### Summary Table

| Doc | Loading Method | When | Manual Read? |
|-----|---------------|------|--------------|
| WORKFLOW-1 | Session-start hook | Every session | âœ— No |
| WORKFLOW-2 | Session-start hook | Every session | âœ— No |
| WORKFLOW-3 | Session-start hook | Every session | âœ— No |
| TESTING-GUIDE | Session-start hook | Every session | âœ— No |
| PROJECT-CONTEXT | Session-start hook | Every session | âœ— No |
| SETUP | Pre-tool-use hook | Backend tool used | âœ— No (auto) |
| MCP-GUIDE | Manual | MCP mentioned | âœ“ YES |
| WORKFLOW-4 | Manual | Emergency | âœ“ YES |
| Templates | Manual | Template needed | âœ“ YES |

---

#### Compliance Checklist

**After Session Start, Verify**:
- [ ] 5 core docs are available (check session-start hook output)
- [ ] You understand all 3 workflows (WORKFLOW-1/2/3)
- [ ] You know test pyramid (TESTING-GUIDE)
- [ ] You know code quality rules (PROJECT-CONTEXT)

**Before Backend Work**:
- [ ] SETUP.md was auto-loaded (check pre-tool-use hook output)
- [ ] venv activation verified
- [ ] No duplicate servers running

**When Context-Dependent Docs Needed**:
- [ ] Manually Read MCP-GUIDE if MCP mentioned
- [ ] Manually Read WORKFLOW-4 if loop detected
- [ ] Manually Read templates if specific format needed

**If ANY checkbox unchecked â†’ Stop and load missing docs**

---

### Subagent Parallel Execution Mechanics

**HOW Parallel Execution Works:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main Agent (You)                                           â”‚
â”‚  Task: "Implement dashboard feature"                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Spawn ALL Subagents in SINGLE Message (Parallel Launch)   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Task tool call #1: "Create types in src/app/types/..."    â”‚
â”‚  Task tool call #2: "Create component in src/app/..."      â”‚
â”‚  Task tool call #3: "Create hooks in src/app/hooks/..."    â”‚
â”‚  Task tool call #4: "Add mock data in src/app/data/..."    â”‚
â”‚  Task tool call #5: "Update App.tsx routing..."            â”‚
â”‚  [ALL 5 calls in ONE message - NOT sequential messages]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Claude Code Orchestrator                                   â”‚
â”‚  Launches 5 subagents SIMULTANEOUSLY in background          â”‚
â””â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”‚      â”‚      â”‚      â”‚      â”‚
  â–¼      â–¼      â–¼      â–¼      â–¼
â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”  â”Œâ”€â”€â”€â”
â”‚ 1 â”‚  â”‚ 2 â”‚  â”‚ 3 â”‚  â”‚ 4 â”‚  â”‚ 5 â”‚  â† Subagents (separate processes)
â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜  â””â”€â”¬â”€â”˜
  â”‚      â”‚      â”‚      â”‚      â”‚     â† Each runs independently
  â”‚      â”‚      â”‚      â”‚      â”‚     â† Each has PostToolUse validation
  â”‚      â”‚      â”‚      â”‚      â”‚     â† Total time = MAX(duration of slowest)
  â–¼      â–¼      â–¼      â–¼      â–¼
Done   Done   Done   Done   Done
  â”‚      â”‚      â”‚      â”‚      â”‚
  â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main Agent Receives ALL Results                            â”‚
â”‚  Duration: ~15 min (not 5Ã—15min = 75min!)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Key Mechanisms:**

1. **Single Message Launch** (CRITICAL):
   ```
   âœ“ CORRECT (Parallel):
   [Message with 5 Task tool calls] â†’ All 5 run simultaneously

   âœ— WRONG (Sequential):
   [Message with Task #1] â†’ wait â†’ [Message with Task #2] â†’ wait...
   ```

2. **Background Execution**:
   - Each subagent runs in a separate process/thread
   - Main agent doesn't wait sequentially
   - Total time = duration of the SLOWEST subagent (not sum of all)

3. **run_in_background: true** (Optional):
   - Can explicitly set `run_in_background: true` on Task tool
   - Use `TaskOutput` to retrieve results later
   - Useful for very long-running tasks (>30 min)

4. **No Dependencies Between Subagents**:
   - Each subagent must work independently
   - No subagent should depend on another's output
   - If dependencies exist, run sequentially instead

---

## Quick Start Guide

### New Session Initialization

**EVERY session starts in plan mode** unless explicitly instructed otherwise.

```bash
# 1. Check git status
git status

# 2. Review active worktrees (if any)
git worktree list

# 3. Review recent workflow performance
cat ~/.claude/metrics/workflow-success.json | jq '.overallSuccessRate'

# 4. Check for improvement suggestions
cat ~/.claude/metrics/improvement-suggestions.md
```

### Essential Commands

| Command | Purpose | When to Use |
|---------|---------|-------------|
| **`/interview`** | **Deep requirements discovery** | **FIRST for new features/architecture (automatic)** |
| `/worktree-setup [name]` | Create feature worktree | Start of any feature/bugfix |
| `/plan-implement-verify` | Full feature cycle | Feature implementation (after interview) |
| `/validate-architecture` | Check code quality | Before committing |
| `/commit-push-pr` | Complete git workflow | After validation passes |
| `/feedback-capture` | Record metrics | End of workflow |

### Default Development Flow (New Features)

```
Interview â†’ Plan â†’ Worktree â†’ Implement (Subagents) â†’ Validate â†’ Commit-Push-PR â†’ Feedback
    â†“        â†“         â†“            â†“                    â†“              â†“              â†“
  Deep    Think    Create     Parallel Execution   PostToolUse    Git Workflow   Metrics
Questions  Mode    Branch      (5-8 subagents)      Validation     Automation    Collection
  + Spec
```

**For detailed workflow documentation**, see: [Workflow Index](.claude/docs/workflows/INDEX.md)

### Simplified Flow (Bug Fixes / Simple Tasks)

```
Plan â†’ Worktree â†’ Implement â†’ Validate â†’ Commit-Push-PR â†’ Feedback
  â†“         â†“            â†“         â†“              â†“              â†“
Think    Create      Execute  PostToolUse    Git Workflow   Metrics
Mode    Branch                Validation     Automation    Collection
```

---

## Subagent Orchestration

### Core Principles

1. **Granular Tasks**: Each subagent = one file/module, <15 min
2. **Parallel Execution**: Launch all subagents in SINGLE message
3. **PostToolUse Validation**: Every subagent change validated automatically
4. **Clear Deliverables**: Exact file path and expected output specified
5. **No Dependencies**: Subagents work independently

### Orchestration Pattern 1: Component Development

```
Main Agent (Oversees architecture)
â”‚
â”œâ”€ Subagent 1: Types (src/app/types/[feature].ts)
â”‚  â”œâ”€ Define interfaces
â”‚  â”œâ”€ Export all types
â”‚  â””â”€ PostToolUse: Type check âœ“
â”‚
â”œâ”€ Subagent 2: Main Component (src/app/components/[Feature].tsx)
â”‚  â”œâ”€ Component structure
â”‚  â”œâ”€ Props with types
â”‚  â””â”€ PostToolUse: Component validation âœ“
â”‚
â”œâ”€ Subagent 3: Sub-Components (src/app/components/[feature]/*)
â”‚  â”œâ”€ Reusable children
â”‚  â”œâ”€ Composition pattern
â”‚  â””â”€ PostToolUse: Component validation âœ“
â”‚
â”œâ”€ Subagent 4: Logic (src/app/hooks/use[Feature].ts)
â”‚  â”œâ”€ Custom React hooks
â”‚  â”œâ”€ State management
â”‚  â””â”€ PostToolUse: Logic validation âœ“
â”‚
â””â”€ Subagent 5: Data (src/app/data/mock[Feature].ts)
   â”œâ”€ Mock data
   â”œâ”€ Matches type definitions
   â””â”€ PostToolUse: Data validation âœ“
```

### Orchestration Pattern 2: Testing Pipeline

```
Main Agent (Test orchestration)
â”‚
â”œâ”€ Subagent 1: Unit Tests
â”‚  â””â”€ Individual function tests
â”‚
â”œâ”€ Subagent 2: Integration Tests
â”‚  â””â”€ Component integration tests
â”‚
â”œâ”€ Subagent 3: E2E Scenarios
â”‚  â””â”€ User flow tests
â”‚
â””â”€ Subagent 4: Test Documentation
   â””â”€ Test coverage report
```

### Orchestration Pattern 3: Code Quality Enforcement

```
Main Agent (Quality gate validation)
â”‚
â”œâ”€ Subagent 1: Type Checking
â”‚  â””â”€ npx tsc --noEmit
â”‚
â”œâ”€ Subagent 2: Lint Validation
â”‚  â””â”€ npx eslint (if configured)
â”‚
â”œâ”€ Subagent 3: Architecture Analysis
â”‚  â””â”€ ~/.claude/hooks/architecture-analyzer.js
â”‚
â””â”€ Subagent 4: Performance Check
   â””â”€ Bundle size, render performance
```

### Spawn Best Practices

**DO**:
```bash
# âœ“ Specific task with file path
/subagent-spawn "Create MetricCard.tsx in src/app/components/dashboard/ with props: metric (DashboardMetric), onClick, className"

# âœ“ Clear success criteria
/subagent-spawn "Add 5 sample dashboard metrics to src/app/data/mockDashboard.ts matching DashboardMetric interface"

# âœ“ Single responsibility
/subagent-spawn "Fix task status update logic in src/app/hooks/useTaskManager.ts line 45-60"
```

**DON'T**:
```bash
# âœ— Too vague
/subagent-spawn "Improve dashboard"

# âœ— Multiple responsibilities
/subagent-spawn "Create component, add types, integrate with app, and test"

# âœ— No file path
/subagent-spawn "Add some metrics"
```

---

## Global Infrastructure

### Overview

This section provides high-level overview of global infrastructure components.
**For detailed documentation, see**: [Infrastructure Index](.claude/docs/infrastructure/INDEX.md)

### PostToolUse Hook

**Purpose**: Automatic validation after every file modification
**Location**: `~/.claude/hooks/post-tool-use.sh`
**Trigger**: Auto-triggered by subagents when `strictMode: true`

**What it validates**:
1. **Type Check** (if TypeScript)
   - Runs: `npx tsc --noEmit`
   - Exits with error if type errors found

2. **Build Validation** (if skipBuild: false)
   - Runs: `npm run build`
   - Exits with error if build fails

3. **Architecture Analysis** (always)
   - Runs: `node ~/.claude/hooks/architecture-analyzer.js`
   - Checks:
     * Unnecessary lines (console.log, debugger, commented code)
     * File size (<800 lines)
     * Function size (<50 lines)
     * Forbidden patterns (any, public fields in classes)
     * OOP principles (God classes, Single Responsibility)
     * Code duplication (DRY violations)
   - Exits with error if issues found (strict mode)

**Configuration**: `~/.claude/hooks/hook-config.json`

**For full validation sequence and configuration**, see:
[PostToolUse Hook Details](.claude/docs/infrastructure/POST-TOOL-USE.md)

---

### Slash Commands

**Purpose**: Reusable workflow automation
**Location**: `~/.claude/commands/*.md`

**Available commands**:

| Command | Purpose | Phase |
|---------|---------|-------|
| `/worktree-setup` | Create isolated feature worktree | Project setup |
| `/plan-implement-verify` | Full feature development cycle | Implementation |
| `/validate-architecture` | Deep code quality analysis | Quality gate |
| `/commit-push-pr` | Complete git workflow | Deployment |
| `/subagent-spawn` | Launch focused subagent | Orchestration |
| `/feedback-capture` | Record workflow metrics | Feedback loop |

**Usage**:
```bash
# Direct invocation
/worktree-setup dashboard-metrics

# Nested in workflows
# /plan-implement-verify includes /worktree-setup, /validate-architecture, /commit-push-pr, /feedback-capture
```

**For detailed command documentation**, see:
[Slash Commands Reference](.claude/docs/infrastructure/SLASH-COMMANDS.md)

---

### Metrics System

**Purpose**: Continuous improvement through feedback loops
**Location**: `~/.claude/metrics/`

**Key files**:

1. **workflow-success.json**
   - Tracks: success rate, duration, failure points per workflow
   - Updated by: `/feedback-capture`
   - Used for: Identifying reliable vs problematic workflows

2. **tool-usage.json**
   - Tracks: tool usage frequency, duration, success rate
   - Updated by: automatic tool call tracking
   - Used for: Identifying underutilized or overused tools

3. **bottlenecks.json**
   - Tracks: recurring issues, delays, blockers
   - Updated by: failure analysis
   - Used for: Prioritizing workflow improvements

4. **improvement-suggestions.md**
   - Tracks: auto-generated improvement suggestions
   - Updated by: metrics analysis (weekly or every 10 workflows)
   - Used for: Guiding CLAUDE.md updates

**Auto-Update Triggers**:

| Trigger | Condition | Action |
|---------|-----------|--------|
| **Failure Pattern** | 3+ workflows fail at same step | Add warning to CLAUDE.md |
| **Unused Tool** | Tool not used in 20+ workflows | Mark as deprecated |
| **New Pattern** | Same approach used 5+ times | Formalize into workflow |
| **Subagent Timeout** | 5+ subagents exceed 15 min | Update task granularity guidance |
| **Architecture Issues** | Same rule violated 3+ times | Add specific rule explanation |

**For metrics system details and auto-update triggers**, see:
[Metrics System Details](.claude/docs/infrastructure/METRICS-SYSTEM.md)

---

## Emergency Procedures (IF-THEN Response)

```
Identify emergency type
    â†“
IF (git conflict detected)
   â†’ STOP current workflow
   â†’ Bash: git status
   â†’ Identify conflicted files
   â†’ IF (simple conflict)
      â†’ Option A: Resolve in-place (edit conflicted files, git add, git commit)
   â†’ ELSE IF (complex conflict)
      â†’ Option B: /worktree-setup recovery-[issue] (clean environment)
   â†’ Resume workflow after resolution
   â†“
ELSE IF (build failure)
   â†’ Bash: npm run build > /tmp/build-errors.log 2>&1
   â†’ Read: /tmp/build-errors.log
   â†’ Grep: Search codebase for error pattern
   â†’ Spawn Subagent: Fix specific error
   â†’ PostToolUse: Validates fix
   â†’ Bash: npm run build (retry)
   â†’ Verify: Build succeeds
   â†“
ELSE IF (infinite loop detected by ralph-wiggum)
   â†’ Auto-Checkpoint: Ralph-wiggum saves state
   â†’ Read: WORKFLOW-4-LOOP-PREVENTION.md
   â†’ Review: Last 10 tool calls
   â†’ Identify: Repeating pattern
   â†’ IF (task too complex)
      â†’ Option A: Simplify (reduce scope, try different method)
   â†’ ELSE IF (same approach repeatedly failing)
      â†’ Option B: Spawn subagent (fresh perspective, PostToolUse catches issues)
   â†’ ELSE IF (unclear requirements)
      â†’ Option C: AskUserQuestion (get guidance)
   â†’ Update: ~/.claude/metrics/bottlenecks.json
   â†’ Resume with new strategy
   â†“
ELSE IF (type check failures)
   â†’ Bash: npx tsc --noEmit > /tmp/tsc-errors.log 2>&1
   â†’ Read: /tmp/tsc-errors.log
   â†’ Identify: Type errors (interface mismatches, missing types, `any` usage)
   â†’ Spawn Subagent: Fix type definitions
   â†’ PostToolUse: Type check validation
   â†’ Verify: All errors resolved
   â†“
ELSE IF (architecture validation failures)
   â†’ Read: ~/.claude/metrics/architecture-report.json
   â†’ Categorize issues:
      - Errors: Must fix before commit (console.log, debugger, any types, files >800 lines)
      - Warnings: Should fix, tech debt acceptable short-term
   â†’ Fix errors: Remove debug statements, split large files, extract reusable functions
   â†’ Bash: /validate-architecture (retry)
   â†’ Verify: Errors resolved
```

---

## Best Practices

### Planning

1. âœ“ **Always start in plan mode** unless explicitly told otherwise
2. âœ“ **Research before implementing**: Grep similar patterns, Read reference files
3. âœ“ **Break down tasks granularly**: 5-8 tasks, each <15 min
4. âœ“ **Design before coding**: Think about architecture, OOP patterns, SOLID principles
5. âœ“ **Get user approval**: AskUserQuestion before major implementation

### Implementation

1. âœ“ **Use worktrees**: Isolate feature work with `/worktree-setup`
2. âœ“ **Parallel subagents**: Launch all in SINGLE message for efficiency
3. âœ“ **PostToolUse validation**: Trust the hook, it catches issues early
4. âœ“ **Incremental testing**: Test components as they're built
5. âœ“ **Manual verification**: Always test in browser before committing

**For code quality standards**, see: [Project Context](.claude/docs/PROJECT-CONTEXT.md)

### Code Quality

1. âœ“ **Single Responsibility**: Each function does ONE thing, <50 lines (ideally <30)
2. âœ“ **Clarity over Cleverness**: Write explicit, readable code for humans
3. âœ“ **Proactive Class Usage**: Use classes for entities with behavior + state, apply OOP patterns
4. âœ“ **SOLID Principles**: Strictly enforce all five principles
5. âœ“ **Type Safety**: Strict TypeScript, zero `any` types
6. âœ“ **No Unnecessary Lines**: Delete unused code, debug statements, excessive comments
7. âœ“ **File Size Limits**: Max 800 lines per file, 300 per component, 50 per function
8. âœ“ **Code Reuse**: Extract duplicated logic (DRY), create reusable classes

**For comprehensive quality standards**, see: [Project Context - Code Quality](.claude/docs/PROJECT-CONTEXT.md#code-quality-standards)

### Git Workflow

1. âœ“ **Atomic commits**: One logical change per commit
2. âœ“ **Descriptive messages**: Explain WHY, not just WHAT
3. âœ“ **Clean history**: Rebase before pushing to avoid merge commits
4. âœ“ **Validate before commit**: `/validate-architecture` passes
5. âœ“ **Link issues**: Reference issue numbers in commits and PRs

**For commit templates**, see: [Commit Message Template](.claude/prompts/commit-message.md)

### Feedback

1. âœ“ **Always capture**: Run `/feedback-capture` after every workflow
2. âœ“ **Be specific**: Include duration, subagent count, observations
3. âœ“ **Review metrics**: Monthly review of success rates and bottlenecks
4. âœ“ **Act on suggestions**: Implement approved improvements from metrics analysis
5. âœ“ **Iterate**: CLAUDE.md evolves based on real usage

---

## Quick Reference

### Most Used Tool Sequences

**Start Feature**:
```bash
/worktree-setup [name] â†’ Grep patterns â†’ Read refs â†’ Think design â†’ Spawn subagents â†’ /validate-architecture â†’ /commit-push-pr â†’ /feedback-capture
```
**Detailed guide**: [Workflow 1: Feature Implementation](.claude/docs/workflows/WORKFLOW-1-FEATURE-IMPLEMENTATION.md)

**Fix Bug**:
```bash
Grep error â†’ Read files â†’ git log â†’ Think fix â†’ /worktree-setup bugfix-[id] â†’ Spawn subagent â†’ /validate-architecture â†’ /commit-push-pr
```
**Detailed guide**: [Workflow 2: Bug Fix](.claude/docs/workflows/WORKFLOW-2-BUG-FIX.md)

**Refactor**:
```bash
/validate-architecture â†’ Read report â†’ Think clean architecture â†’ /worktree-setup refactor-[area] â†’ Spawn subagents â†’ /validate-architecture â†’ Compare before/after â†’ /commit-push-pr
```
**Detailed guide**: [Workflow 3: Refactoring](.claude/docs/workflows/WORKFLOW-3-REFACTORING.md)

**Prevent Loops**:
```bash
Ralph-wiggum detects loop â†’ Auto-checkpoint â†’ Analyze pattern â†’ Try alternative â†’ Resume OR Ask user
```
**Detailed guide**: [Workflow 4: Loop Prevention](.claude/docs/workflows/WORKFLOW-4-LOOP-PREVENTION.md)

---

### Essential File Paths

**Core Configuration**:
- This guide: `/Users/jaewookim/Desktop/Personal Coding/AI Audit/CLAUDE.md`
- Documentation index: `.claude/docs/INDEX.md`
- Workflow index: `.claude/docs/workflows/INDEX.md`
- Template index: `.claude/prompts/INDEX.md`

**Global Infrastructure**:
- Hooks: `~/.claude/hooks/*.sh`, `~/.claude/hooks/*.js`
- Commands: `~/.claude/commands/*.md`
- Metrics: `~/.claude/metrics/*.json`, `~/.claude/metrics/*.md`
- Config: `~/.claude/hooks/hook-config.json`

**Project-Local**:
- Frontend: `/Users/jaewookim/Desktop/Personal Coding/AI Audit/frontend/`
- Worktrees: `/Users/jaewookim/Desktop/Personal Coding/AI Audit/worktrees/`
- Backend: `/Users/jaewookim/Desktop/Personal Coding/AI Audit/backend/` (placeholder)

---

### Common References

**Quick Links for Frequent Lookups**:

| Need | Reference |
|------|-----------|
| **Workflow steps** | [Workflow Index](.claude/docs/workflows/INDEX.md) |
| **MCP server usage** | [MCP Integration Guide](.claude/docs/MCP-GUIDE.md) |
| **Testing methodology** | [Testing Strategy](.claude/docs/TESTING-GUIDE.md) |
| **Environment setup** | [Development Environment](.claude/docs/SETUP.md) |
| **Code quality rules** | [Project Context](.claude/docs/PROJECT-CONTEXT.md#code-quality-standards) |
| **Commit format** | [Commit Message Template](.claude/prompts/commit-message.md) |
| **PR format** | [PR Description Template](.claude/prompts/pr-description.md) |
| **Subagent spawning** | [Subagent Spawn Template](.claude/prompts/subagent-spawn.md) |
| **Architecture review** | [Architecture Review Template](.claude/prompts/architecture-review.md) |

**Token Savings**:
- Core CLAUDE.md: ~1,220 lines (reduced from 2,766 lines)
- Reduction: **56% smaller** while preserving ALL content
- External docs: ~1,546 lines (on-demand loading)
- Total preserved: 2,766 lines (no content loss)

---

## ðŸ“š External References

### Core Documentation

- **[Documentation Index](.claude/docs/INDEX.md)** - Central navigation hub
- **[MCP Integration Guide](.claude/docs/MCP-GUIDE.md)** - MCP servers, auto-use triggers, best practices (436 lines)
- **[Testing Strategy](.claude/docs/TESTING-GUIDE.md)** - Test pyramid, coverage requirements, assertions (303 lines)
- **[Development Environment](.claude/docs/SETUP.md)** - Python venv, server management, checklist (131 lines)
- **[Project Context](.claude/docs/PROJECT-CONTEXT.md)** - Tech stack, file organization, code quality standards (174 lines)

### Workflows (652 lines total)

- **[Workflow Index](.claude/docs/workflows/INDEX.md)** - All workflows overview
- **[Workflow 1: Feature Implementation](.claude/docs/workflows/WORKFLOW-1-FEATURE-IMPLEMENTATION.md)** - 10-15 parallel subagents, 8 phases
- **[Workflow 2: Bug Fix](.claude/docs/workflows/WORKFLOW-2-BUG-FIX.md)** - Fast-track resolution, 6 phases
- **[Workflow 3: Refactoring](.claude/docs/workflows/WORKFLOW-3-REFACTORING.md)** - Architecture improvement, 6 phases
- **[Workflow 4: Loop Prevention](.claude/docs/workflows/WORKFLOW-4-LOOP-PREVENTION.md)** - Ralph-Wiggum recovery, 5 steps

### Templates (200 lines total)

- **[Template Index](.claude/prompts/INDEX.md)** - All templates overview
- **[Subagent Spawn Template](.claude/prompts/subagent-spawn.md)** - Pattern for spawning subagents
- **[Workflow Breakdown Template](.claude/prompts/workflow-breakdown.md)** - 10-15 task breakdown
- **[Commit Message Template](.claude/prompts/commit-message.md)** - Standardized commit format
- **[PR Description Template](.claude/prompts/pr-description.md)** - Pull request template
- **[Architecture Review Template](.claude/prompts/architecture-review.md)** - Quality checklist

### Infrastructure (123 lines total)

- **[Infrastructure Index](.claude/docs/infrastructure/INDEX.md)** - Infrastructure overview
- **[PostToolUse Hook](.claude/docs/infrastructure/POST-TOOL-USE.md)** - Automatic validation details
- **[Slash Commands](.claude/docs/infrastructure/SLASH-COMMANDS.md)** - Command reference
- **[Metrics System](.claude/docs/infrastructure/METRICS-SYSTEM.md)** - Feedback loop details

### Usage Notes

**When to reference external docs**:
- âœ“ When you need detailed workflow steps â†’ Workflows
- âœ“ When you need MCP tool specifics â†’ MCP Guide
- âœ“ When you need testing methodology â†’ Testing Guide
- âœ“ When you need environment setup help â†’ Setup Guide
- âœ“ When you need a template â†’ Templates

**Auto-loading behavior**:
- âœ— External docs are NOT auto-loaded every session
- âœ“ Core CLAUDE.md IS auto-loaded every session
- âœ“ Reference external docs on-demand when needed
- âœ“ Links are relative paths (work from any location)

---

**Remember**: This modular structure preserves all content while reducing token usage by 56%. Core philosophy and orchestration remain immediately accessible, while detailed reference material is one click away.

**Support**:
1. Check [Emergency Procedures](#emergency-procedures) for common issues
2. Review `~/.claude/metrics/improvement-suggestions.md` for workflow improvements
3. Consult global slash commands in `~/.claude/commands/`
4. Update this CLAUDE.md with new learnings via feedback loop
